# conf/config.yaml

hyperparameters:
  batch_size: 64
  learning_rate: 1e-4
  optimizer: torch.optim.Adam
  lr: 1e-3
  criterion: torch.nn.CrossEntropyLoss

trainer:
  max_epochs: 50
  limit_train_batches: 0.2
  accelerator: cpu
  check_val_every_n_epoch: 2